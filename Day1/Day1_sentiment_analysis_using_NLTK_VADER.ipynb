{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4940b47",
   "metadata": {},
   "source": [
    "This notebook showcases how to perform sentiment analysis on Amazon reviews using the VADER(Valence Aware Dictionary and Sentiment Reasoner) sentiment analysis tool from the Natural Language Toolkit (NLTK). VADER is a lexicon and rule-based sentiment analysis tool specifically designed to analyze social media texts but can be effectively applied to other domains, such as product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation: Natural Language Tool Kit\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb6aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time\n",
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e980fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is a one of the best apps acording to a b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a pretty good version of the game for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is a really cool game. there are a bunch ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a silly game and can be frustrating, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a terrific game on any pad. Hrs of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>this app is fricken stupid.it froze on the kin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>Please add me!!!!! I need neighbors! Ginger101...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>love it!  this game. is awesome. wish it had m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>I love love love this app on my side of fashio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>This game is a rip off. Here is a list of thin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              reviewText  Positive\n",
       "0      This is a one of the best apps acording to a b...         1\n",
       "1      This is a pretty good version of the game for ...         1\n",
       "2      this is a really cool game. there are a bunch ...         1\n",
       "3      This is a silly game and can be frustrating, b...         1\n",
       "4      This is a terrific game on any pad. Hrs of fun...         1\n",
       "...                                                  ...       ...\n",
       "19995  this app is fricken stupid.it froze on the kin...         0\n",
       "19996  Please add me!!!!! I need neighbors! Ginger101...         1\n",
       "19997  love it!  this game. is awesome. wish it had m...         1\n",
       "19998  I love love love this app on my side of fashio...         1\n",
       "19999  This game is a rip off. Here is a list of thin...         0\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing required librarires\n",
    "import pandas as pd\n",
    "import nltk\n",
    "# for preprocessing the text \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Vader rule based tool to analyse the sentiment of the text\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# gathering dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/amazon.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    '''\n",
    "    Function to preprocess the input text by removing stop words which doesnot signify any emotions and reducing words to the base form using lemmatisation and stemming.\n",
    "    '''\n",
    "    token_words = word_tokenize(text)\n",
    "    filtered_tokens = [token for token in token_words if token.lower() not in stopwords.words('english')]\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatiser.lemmatize(token) for token in filtered_tokens]\n",
    "    preprocessed_text = ' '.join(lemmatized_text)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abce991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviewText'] = df['reviewText'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d62c3cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one best apps acording bunch people agree bomb...\n",
       "1    pretty good version game free . LOTS different...\n",
       "2    really cool game . bunch level find golden egg...\n",
       "3    silly game frustrating , lot fun definitely re...\n",
       "4    terrific game pad . Hrs fun . grandkids love ....\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviewText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ae6dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading vader rule based sentiment analyser\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def get_sentiment(text):\n",
    "    \n",
    "    # getting compound score for each text which is a normalised score between -1 & 1 to which defines the sentiment\n",
    "    scores = analyser.polarity_scores(text)\n",
    "    print(scores)\n",
    "    # if compound score >0.05 positive comments else negative\n",
    "    sentiment = 1.0 if scores['compound'] > 0.05 else 0\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b2be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['reviewText'].apply(get_sentiment)\n",
    "df['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b8539",
   "metadata": {},
   "source": [
    "Evaluation - accuracy, precision, recall using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "080dc1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      4767\n",
      "           1       0.88      0.89      0.88     15233\n",
      "\n",
      "    accuracy                           0.82     20000\n",
      "   macro avg       0.75      0.74      0.75     20000\n",
      "weighted avg       0.82      0.82      0.82     20000\n",
      "\n",
      "[[ 2833  1934]\n",
      " [ 1662 13571]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(df['Positive'], df['sentiment']))\n",
    "print(confusion_matrix(df['Positive'], df['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3bcee8",
   "metadata": {},
   "source": [
    "Conclusion : VADER is a rule-based sentiment analyzer with approximately 82% accuracy, primarily effective for social media analysis. Accuracy can be enhanced using machine learning models or hybrid approaches that integrate contextual understanding and domain-specific lexicon tweaks. Advanced NLP techniques, such as transformers, also help in capturing nuanced sentiments and improving overall performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
